# 遥感图像识别

## 一. 概要

使用Python作为编程语言

各种模型的实现基于[scikit-learn](https://scikit-learn.org/stable/index.html)

挑选了5个模型进行遥感图像的识别，分别是

- SVM

- 朴素贝叶斯

- 全连接神经网络

- 决策树

- K近邻

  本次作业没有使用图像识别的一个常用模型-卷积神经网络的原因是，由于采用数据集的图像很大(300x300)相比于MNIST或是CIFAR来说，像素点的数目多了十倍以上，卷积神经网络处理这个数据量在我的电脑上运行速度太慢，所以没有分析卷积神经网络的效果。

  文档第三部分介绍5个模型的参数和分类效果，然后第四部分总结对比这个5个模型.

## 二. 数据集处理

选用的原始数据集为 [AID](http://captain.whu.edu.cn/project/AID/)，原始数据集包含30类的遥感图像数据，每一张图像的大小为600x600像素，每一类有大约200张图片，但限于机器的性能，并且考虑到原始数据集过于庞大，所以将原始数据集做了一些处理。

- 首先读取原始图像数据，使用Python的PIL模块中的函数将图像转化为300x300的灰度图，转化后虽然有信息丢失，但大幅提高了各模型的训练效率。

转化前：![airport_1](E:\Machine Learning\Remote sensing\Dataset\AID\Airport\airport_1.jpg)

转化后：

![test](E:\Machine Learning\Remote sensing\Dataset\test.jpg)

- 将灰度图数据拉直为1维数组
- 然后在各类别中取120张图片的数据作为训练集，再取另外30张图片数据作为测试集。
- 最后对训练集数据的顺序做一个随机调整，使用numpy存储为npz格式的文件。

最终的数据集为：

> 训练集样本数: 3600（每一类为120）
>
> 测试集样本数: 900（每一类为30）
>
> 样本类别数: 30
>
> 单个样本大小: 90000

30个类别分别为(从0开始编号)：

> 0. airport
> 1. bare land
> 2. baseball field
> 3. beach
> 4. bridge
> 5. center
> 6. church 
> 7. commercial 
> 8. dense residential
> 9. desert 
> 10. farmland
> 11. forest
> 12. industrial
> 13. meadow
> 14. medium residential 
> 15. mountain
> 16. park
> 17. parking
> 18. playground
> 19. pond
> 20. port
> 21. railway station
> 22. resort
> 23. river
> 24. school
> 25. sparse residential
> 26. square
> 27. stadium
> 28. storage tanks
> 29. viaduct

图像预览：

![http://captain.whu.edu.cn/project/AID/aid-dataset.png](http://captain.whu.edu.cn/project/AID/aid-dataset.png)

## 三. 模型分类结果

### 1. 支持向量机

对于高维空间，尤其是数据维度（90000）大于样本数量（3600）的时候，我首先想到的模型就是SVM，因为我的样本数较少，而SVM不像神经网络需要大量的数据才能达到一个好的效果，SVM训练出的模型仅与样本中的几个支持向量有关，所以我首先测试了SVM的分类效果。

使用的SVM核函数为高斯核函数，并且多分类的策略我选择了'one-against-one'策略，即对于30个类别构建30x(30-1)/2 = 435个分类器。

分类报告：

>              precision    recall  f1-score   support
>    
>           0       0.10      0.03      0.05        30
>           1       0.29      0.53      0.38        30
>           2       0.06      0.03      0.04        30
>           3       0.48      0.33      0.39        30
>           4       0.36      0.17      0.23        30
>           5       0.67      0.80      0.73        30
>           6       0.34      0.40      0.37        30
>           7       0.02      0.03      0.02        30
>           8       0.35      0.30      0.32        30
>           9       0.75      0.60      0.67        30
>          10       0.13      0.20      0.16        30
>          11       0.44      0.80      0.56        30
>          12       0.16      0.23      0.19        30
>          13       0.29      0.67      0.40        30
>          14       0.13      0.13      0.13        30
>          15       0.00      0.00      0.00        30
>          16       0.47      0.30      0.37        30
>          17       0.62      0.17      0.26        30
>          18       0.30      0.10      0.15        30
>          19       0.44      0.27      0.33        30
>          20       0.09      0.07      0.08        30
>          21       0.13      0.07      0.09        30
>          22       0.00      0.00      0.00        30
>          23       0.10      0.23      0.14        30
>          24       0.21      0.23      0.22        30
>          25       0.30      0.53      0.38        30
>          26       0.43      0.60      0.50        30
>          27       0.79      0.63      0.70        30
>          28       0.25      0.20      0.22        30
>          29       0.07      0.03      0.04        30
>    
>    accuracy                           0.29       900
>    macro avg      0.29      0.29      0.27       900
>    weighted avg   0.29      0.29      0.27       900

运行时间：

> train_time = 2259.3590325 s
>
> test_time = 408.9927550000002 s

由分类报告可以看到，SVM模型在整个测试集上的准确率为29%，这也是5个模型中准确率最高的，如果随机分类的话，对30类的样本准确率为3.3%，因为每一类样本的数量相等，所以宏平均和微平均的值相同。

SVM模型在第5类、第9类、第27类上的分类效果最好，这三类分别是center, desert, stadium

对于第15类moutain和第22类resort，模型的查准率和查全率都为0，表示模型没有将任何一个样本识别为这两个类别。

对于第2类baseball field、第7类commercial，第29类viaduct，模型的查准率很低，表示模型会将很多其他类的图片错误的分到这一类。

### 2. 朴素贝叶斯

我使用了高斯朴素贝叶斯，即先验概率由高斯分布计算出。因为我的样本特征值经过归一化后是0-1连续分布的值，所以选择了更适合连续特征值的高斯朴素贝叶斯，其他两种朴素贝叶斯（多项式朴素贝叶斯、伯努利朴素贝叶斯）我也尝试过，整个分类效果都逊于高斯朴素贝叶斯。

分类报告：

>               precision    recall  f1-score   support
>     
>            0       0.08      0.03      0.05        30
>            1       0.26      0.57      0.35        30
>            2       0.20      0.07      0.10        30
>            3       0.10      0.17      0.13        30
>            4       0.00      0.00      0.00        30
>            5       0.69      0.73      0.71        30
>            6       0.25      0.23      0.24        30
>            7       0.00      0.00      0.00        30
>            8       0.26      0.30      0.28        30
>            9       0.77      0.57      0.65        30
>           10       0.10      0.27      0.15        30
>           11       0.42      0.83      0.56        30
>           12       0.16      0.23      0.19        30
>           13       0.21      0.57      0.30        30
>           14       0.07      0.03      0.05        30
>           15       0.00      0.00      0.00        30
>           16       0.18      0.07      0.10        30
>           17       0.23      0.10      0.14        30
>           18       0.47      0.30      0.37        30
>           19       0.09      0.10      0.09        30
>           20       0.23      0.10      0.14        30
>           21       0.15      0.07      0.09        30
>           22       0.08      0.03      0.05        30
>           23       0.07      0.17      0.10        30
>           24       0.24      0.17      0.20        30
>           25       0.27      0.50      0.35        30
>           26       0.32      0.20      0.24        30
>           27       0.83      0.50      0.62        30
>           28       0.40      0.27      0.32        30
>           29       0.08      0.03      0.05        30
>     
>     accuracy                           0.24       900
>     macro avg      0.24      0.24      0.22       900
>     weighted avg   0.24      0.24      0.22       900

运行时间：

> train_time = 6.253295499999998 s
>
> test_time = 31.1875406 s

由分类报告可以看出朴素贝叶斯的准确率为24%，稍低于SVM的准确率，为5个模型中准确率第二高的模型。

朴素贝叶斯在第5类center、第9类desert、第27类stadium的分类效果最好，这点与SVM的结果相同。

而对于第4类bridge、第7类commercial、第15类mountain的查准率查全率均为0，模型没有将任何一个测试样本识别为这3个类别。

查准率较低的类分别为第14类medium residential和第23类river，模型在这两个类上的错误率很高。

另外值得注意的一点是，朴素贝叶斯的运行效率非常高，训练时间只有6秒，而在预测测试集的时间为31秒。

### 3. 神经网络

第3个模型我选用的是单隐层全连接神经网络，因为受运行时间的限制，无法采用更复杂的网络结构，神经网络的参数为：

> 优化算法：梯度下降
>
> batch_size = 200
>
> 激活函数： tanh
>
> 学习率：固定值0.001
>
> 隐层结点数： 300
>
> 正则化参数： 0.00001
>
> 迭代次数： 100

分类报告：

>               precision    recall  f1-score   support
>     
>            0       0.11      0.10      0.10        30
>            1       0.14      0.33      0.20        30
>            2       0.09      0.07      0.08        30
>            3       0.13      0.13      0.13        30
>            4       0.14      0.17      0.15        30
>            5       0.46      0.83      0.60        30
>            6       0.09      0.03      0.05        30
>            7       0.00      0.00      0.00        30
>            8       0.00      0.00      0.00        30
>            9       0.40      0.97      0.56        30
>           10       0.04      0.07      0.05        30
>           11       0.50      0.57      0.53        30
>           12       0.38      0.10      0.16        30
>           13       0.11      0.53      0.19        30
>           14       0.09      0.03      0.05        30
>           15       0.00      0.00      0.00        30
>           16       0.24      0.17      0.20        30
>           17       0.00      0.00      0.00        30
>           18       0.10      0.07      0.08        30
>           19       0.11      0.17      0.14        30
>           20       0.00      0.00      0.00        30
>           21       0.14      0.07      0.09        30
>           22       0.15      0.07      0.09        30
>           23       0.06      0.10      0.07        30
>           24       0.10      0.07      0.08        30
>           25       0.36      0.30      0.33        30
>           26       0.13      0.07      0.09        30
>           27       0.53      0.70      0.60        30
>           28       0.25      0.10      0.14        30
>           29       0.00      0.00      0.00        30
>     
>     accuracy                           0.19       900
>     macro avg      0.16      0.19      0.16       900
>     weighted avg   0.16      0.19      0.16       900

运行时间：

> train_time = 2410.4872697
>
> test_time = 2.543681600000127

该全连接神经网络在整个测试集上的准确率为19%，低于SVM和朴素贝叶斯的模型。

分类效果最好的类别是第5类center、第9类desert、第27类stadium，与前两个模型相同。

查准率和查全率均为0的类别是第7类commercial、第8类dense residential、第15类mountain、第17类parkin给、第29类viaduct。

在第10类farmland、第23类river的查准率较低，神经网络模型会将更多的其他类错误的分到这两个类别。

神经网络的训练时间和测试样本时间与SVM相差不大。

### 4. 决策树

第4个模型我选择了决策树，其中分裂结点的评价标准是Gini指数。

决策树对于图像识别的效果应该是比较差的，因为样本的特征值远大于样本数量，很容易造成决策树的过拟合，可以通过限制决策树的深度来减小过拟合，sklearn的模型也提供了相应的参数，但限于测试时间，我这里没有进一步调整参数。

分类报告：

>               precision    recall  f1-score   support
>     
>            0       0.14      0.13      0.14        30
>            1       0.15      0.20      0.17        30
>            2       0.09      0.10      0.10        30
>            3       0.05      0.03      0.04        30
>            4       0.06      0.07      0.06        30
>            5       0.32      0.33      0.33        30
>            6       0.17      0.17      0.17        30
>            7       0.11      0.13      0.12        30
>            8       0.09      0.07      0.08        30
>            9       0.53      0.57      0.55        30
>           10       0.04      0.07      0.05        30
>           11       0.44      0.37      0.40        30
>           12       0.11      0.10      0.10        30
>           13       0.27      0.50      0.35        30
>           14       0.12      0.13      0.12        30
>           15       0.00      0.00      0.00        30
>           16       0.00      0.00      0.00        30
>           17       0.03      0.03      0.03        30
>           18       0.04      0.03      0.04        30
>           19       0.12      0.13      0.13        30
>           20       0.12      0.10      0.11        30
>           21       0.00      0.00      0.00        30
>           22       0.00      0.00      0.00        30
>           23       0.11      0.13      0.12        30
>           24       0.00      0.00      0.00        30
>           25       0.19      0.13      0.16        30
>           26       0.07      0.07      0.07        30
>           27       0.32      0.23      0.27        30
>           28       0.06      0.07      0.06        30
>           29       0.00      0.00      0.00        30
>     
>     accuracy                           0.13       900
>     macro avg      0.13      0.13      0.13       900
>     weighted avg   0.13      0.13      0.13       900

运行时间：

> train_time = 493.37681399999997
>
> test_time = 0.32019530000002305

可以看出决策树的分类效果已经比较差了，在测试集上的准确率只有13%。

决策树在第九类desert上的分类效果最好，f1-score超过了0.5

查准率与查全率均为0的类为，15-mountain，16-park，21-railway station，22-resort，29-viaduct

查准率不为0但很低的类为，10-farmland，17-parking，18-playground

另外决策树的生成效率要高于SVM和神经网络，测试效率也很高，这点可以理解，决策树在预测阶段的计算量要远小于其他模型。

### 5. K近邻

最后一个模型我选择了k近邻算法，k近邻算法是一个相对简单的算法，该模型的效率与k值有很大的关系，限于运行时间，我只尝试了10、15两个k值，最终k=10时分类效果最好，对距离度量的定义，采用的是闵可夫斯基距离也是sklearn决策树模型的默认距离度量方式。

分类报告：

>               precision    recall  f1-score   support
>     
>            0       0.00      0.00      0.00        30
>            1       0.09      0.63      0.16        30
>            2       0.00      0.00      0.00        30
>            3       0.89      0.27      0.41        30
>            4       0.00      0.00      0.00        30
>            5       1.00      0.30      0.46        30
>            6       0.00      0.00      0.00        30
>            7       0.00      0.00      0.00        30
>            8       0.00      0.00      0.00        30
>            9       0.30      0.93      0.45        30
>           10       0.00      0.00      0.00        30
>           11       0.83      0.17      0.28        30
>           12       0.00      0.00      0.00        30
>           13       0.04      0.80      0.08        30
>           14       0.00      0.00      0.00        30
>           15       0.00      0.00      0.00        30
>           16       0.00      0.00      0.00        30
>           17       0.00      0.00      0.00        30
>           18       0.00      0.00      0.00        30
>           19       1.00      0.03      0.06        30
>           20       0.00      0.00      0.00        30
>           21       0.00      0.00      0.00        30
>           22       0.00      0.00      0.00        30
>           23       0.00      0.00      0.00        30
>           24       0.00      0.00      0.00        30
>           25       0.00      0.00      0.00        30
>           26       0.00      0.00      0.00        30
>           27       1.00      0.10      0.18        30
>           28       0.00      0.00      0.00        30
>           29       0.00      0.00      0.00        30
>     
>     accuracy                           0.11       900
>     macro avg      0.17      0.11      0.07       900
>     weighted avg   0.17      0.11      0.07       900

运行时间：

> train_time = 88.3337988
>
> test_time = 465.89388799999995

k近邻模型的准确率只有11%，是5个模型中最低的，并且对于大多数类的查准率与查全率都为0，他只会把测试样本预测为个别的几个类中（1，3，5，9，11，13，19，27），这个现象我目前难以找到合理的解释。

k近邻算法的训练时间较短，因为k近邻算法的训练过程就是保存训练集数据的过程，然而预测样本的时间较长，因为样本的特征维度相当大，所以计算样本闵可夫斯基距离的时间也相当长，还需要占用大量的内存。

还有值得注意的一点就是训练出k近邻模型用sklearn的joblib模块存在磁盘上的时候，模型文件相当大，有接近5个G的大小。

## 四. 总结与比较

### 1. 遇到的问题

在初期模型的训练过程中，我首先尝试使用了期中作业时写的神经网络模型，发现模型的最终准确率只有不到4%，与随机猜得到的准确率几乎相同，然后尝试调整网络的各项参数还是得不到改善，更换了SVM模型之后还是几乎相同的准确率，最后发现问题的所在就是数据集没有归一化，灰度图的像素值我保存成了0-255的数据，导致神经网络和SVM的训练效果很差。

### 2. 数据集的特点与模型参数的选择

由于我这次采用的数据集是（300x300）的灰度图，训练样本数只有3600个，可见该数据集的样本数远远小于样本的特征数，而SVM的核函数我选择的是高斯核函数，在查阅资料之后了解到对于这种超高维度的数据选择线性核函数较为合理，运行速度也会有所提高，但我后来尝试了线性核函数之后发现准确率变化不大。

sklearn封装的朴素贝叶斯有三种，分别是高斯朴素贝叶斯、多项式朴素贝叶斯、伯努利朴素贝叶斯，对于连续分布的特征值，选择高斯朴素贝叶斯最优，对于离散分布的特征值，选择多项式朴素贝叶斯更好，而伯努利则适合于0-1离散的的特征值，我的数据集经过归一化之后更偏向于连续分布，所以选择了高斯朴素贝叶斯。

### 3. 分类效果比较

| 模型(准确率)        | 效果较好的类 | 错误较多的类（查准率较低） | 查准率查全率都为0  |
| ------------------- | :----------: | :------------------------: | :----------------: |
| SVM（29%）          |   5，9，27   |          2，7，29          |       15，22       |
| 高斯朴素贝叶斯(24%) |   5，9，27   |           14，23           |      4，7，15      |
| 全连接神经网络(19%) |   5，9，27   |           10，23           |  7，8，15，17，29  |
| 决策树（13%）       |      9       |         10，17，18         | 15，16，21，22，29 |
| k近邻（11%）        |   3，5，9    |            很多            |        很多        |

由上表对比可以看出所有模型几乎都对5，9，27三类有相对较好的识别效果，即这三类的f1-score较高，说明这3类图像本身就有较好的辨识性，与模型的特性没有太大的关系。

5-center、9-desert、27-stadium：

![1561704875721](C:\Users\22123\AppData\Roaming\Typora\typora-user-images\1561704875721.png)

![1561704923307](C:\Users\22123\AppData\Roaming\Typora\typora-user-images\1561704923307.png)

![1561704936226](C:\Users\22123\AppData\Roaming\Typora\typora-user-images\1561704936226.png)

比较有趣的一点是所有模型对于15这一类的查准率和查全率都为0，说明没有任何一个模型将测试样本预测为此类。

15-mountain：

![1561704959916](C:\Users\22123\AppData\Roaming\Typora\typora-user-images\1561704959916.png)

错误预测较多的类在这5个模型中虽然各不相同，但从预览图中可以看出错误预测大都偏向于图片纹理复杂细节较多的类，如：

![1561705896655](C:\Users\22123\AppData\Roaming\Typora\typora-user-images\1561705896655.png)

![1561705917187](C:\Users\22123\AppData\Roaming\Typora\typora-user-images\1561705917187.png)

从准确率上来看，前四个模型的准确率都比较正常，SVM最高而后是朴素贝叶斯、神经网络和决策树，如果使用了卷积神经网络还可能得到更高的准确率。

但是对KNN模型，准确率有点偏低，因为我的数据集个样本数量是均匀的，所以还是比较适合KNN算法，理论上来说KNN模型不应该只有11%的准确率，这可能也与k值的选择有关，k值决定的是最后取k个距离最近的训练样本数据投票，我对于k值的选择没有经验而且限于运行时间，没有尝试更多的k值，另外一个我猜想可改进的方向是，KNN模型的投票方式的选择，我使用的是均匀投票方式，就是最后k个样本点的权重相同，而这里可以考虑使用距离反比的权重投票方式。

决策树的准确率较低也在意料之中，因为决策树本身的算法特性就不太适用于超高维度的样本特征空间，而我的数据集样本数又相对较少，远远小于样本特征数，所以普通的决策树模型很容易造成过拟合，最终决策树模型也只有13%的准确率，仅仅高于KNN算法模型，为防止过拟合，之后的改进的方向可以考虑限制决策树的层数，或从剪枝函数入手。

全连接神经网络的训练次数我只设置了100次，因为运行时间太长，但根据损失函数的变化可以看到模型可能还没有收敛到稳定的状态。

在这5个模型中SVM取得最高的准确率也应当与数据集本身的特点有关，因为SVM自身的分类方式只取决于几个特征向量，所以它对数据集样本数不是很敏感，相对于神经网络来说，所以SVM模型在我的数据集中有较好表现。

朴素贝叶斯模型虽然准确率稍低于SVM，但是它有着相当快的运行效率，比较模型的训练时间可知，朴素贝叶斯训练时间为6秒，而SVM和神经网络的训练时间都在2000秒以上，并且预测样本的时间朴素贝叶斯也只有31秒，所以总体的运行效率朴素贝叶斯比SVM和神经网络快了接近100倍，朴素贝叶斯模型在这个数据集上兼顾了运行时间和准确率。另外朴素贝叶斯假设了各样本特征是独立的，而在图像数据中，这个假设应当是不成立的，所以或许可以考虑半朴素贝叶斯来获得更高的准确率。

另外KNN和决策树由于本身的算法思想简单易于理解，运行的时间也稍短，不同的是决策树生成过程较为费时，而KNN模型的训练过程简单，而预测过程需要计算样本距离较为费时。